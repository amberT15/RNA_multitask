{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "sys.path.append('/home/ztang/multitask_RNA/data_generation')\n",
    "import utils \n",
    "import numpy as np\n",
    "datalen = '230'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(\"/home/ztang/multitask_RNA/data/CAGI/\"+datalen+\"/CAGI_onehot.h5\", \"r\")\n",
    "alt = file['alt']\n",
    "ref = file['ref']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nucleotide Transformer zero shot test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine similarity between embeddings with different allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2B5_model\n"
     ]
    }
   ],
   "source": [
    "import nucleotide_transformer\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from nucleotide_transformer.pretrained import get_pretrained_model\n",
    "from tqdm import tqdm\n",
    "model_name = '2B5_1000G'\n",
    "\n",
    "if '2B5' in model_name:\n",
    "    print('2B5_model')\n",
    "    embed_layer = 32\n",
    "else:\n",
    "    print('500M model')\n",
    "    embed_layer = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = math.ceil(len(alt[0])/6)+2\n",
    "parameters, forward_fn, tokenizer, config = get_pretrained_model(\n",
    "    model_name=model_name,\n",
    "    mixed_precision=False,\n",
    "    embeddings_layers_to_save=(embed_layer,),\n",
    "    attention_maps_to_save=(),\n",
    "    max_positions=max_len,\n",
    ")\n",
    "forward_fn = hk.transform(forward_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [03:09<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# CLS = 3\n",
    "# PAD = 2\n",
    "random_key = jax.random.PRNGKey(0)\n",
    "N, L, A = alt.shape\n",
    "batch_size = 200\n",
    "cagi_llr=[]\n",
    "for i in tqdm(range(0,N,batch_size)):\n",
    "    b_size = batch_size\n",
    "    if i + batch_size > N:\n",
    "        b_size = N-i\n",
    "    onehot = np.concatenate((ref[i:i+b_size],alt[i:i+b_size]))\n",
    "    seq = utils.onehot_to_seq(onehot)\n",
    "    token_out = tokenizer.batch_tokenize(seq)\n",
    "    token_id = [b[1] for b in token_out]\n",
    "    seq_pair = jnp.asarray(token_id,dtype=jnp.int32)\n",
    "    outs = forward_fn.apply(parameters, random_key, seq_pair)\n",
    "    for a in range(b_size):\n",
    "        ref_out = outs['embeddings_'+str(embed_layer)][a, 1:, :]\n",
    "        alt_out = outs['embeddings_'+str(embed_layer)][a+b_size, 1:, :]\n",
    "        # mean_alt = jnp.sum(alt_out, axis=1) \n",
    "        # mean_ref = jnp.sum(ref_out, axis=1) \n",
    "        # cagi_llr.append((mean_ref * mean_alt).sum()/(jnp.linalg.norm(mean_ref)*jnp.linalg.norm(mean_alt)))\n",
    "        cagi_llr.append((ref_out * alt_out).sum()/(jnp.linalg.norm(ref_out)*jnp.linalg.norm(alt_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/'+datalen+'/cagi_'+model_name+'.h5', 'w')\n",
    "output.create_dataset('llr', data=np.array(cagi_llr))\n",
    "output.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats\n",
    "model_name = '500M_1000G'\n",
    "input_length = '230'\n",
    "cagi_df = pd.read_csv('../../data/CAGI/'+input_length+'/final_cagi_metadata.csv',\n",
    "                      index_col=0).reset_index()\n",
    "exp_list = cagi_df['8'].unique()\n",
    "target = cagi_df['6'].values.tolist()\n",
    "plot_figure=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagi_result = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/'+input_length+'/cagi_'+model_name+'.h5', 'r')\n",
    "cagi_llr = cagi_result['llr'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZFAND3\n",
      "-0.0032445862816593684\n",
      "HBG1\n",
      "0.012777808439967672\n",
      "MSMB\n",
      "-0.003442195277169142\n",
      "LDLR\n",
      "0.019409858282437277\n",
      "MYCrs6983267\n",
      "-0.010262244619401712\n",
      "SORT1\n",
      "0.0181933016993205\n",
      "PKLR\n",
      "0.0538593500221866\n",
      "F9\n",
      "0.043339159835804185\n",
      "TERT-HEK293T\n",
      "-0.007765231618602955\n",
      "IRF6\n",
      "0.007473439548794598\n",
      "HBB\n",
      "0.018034245722466917\n",
      "TERT-GBM\n",
      "0.014877822453121033\n",
      "IRF4\n",
      "0.02228980885475156\n",
      "GP1BB\n",
      "0.018055375665325012\n",
      "HNF4A\n",
      "-0.029653319901501378\n"
     ]
    }
   ],
   "source": [
    "perf = []\n",
    "sanity_check = 0\n",
    "for exp in cagi_df['8'].unique():\n",
    "    sub_df = cagi_df[cagi_df['8'] == exp]\n",
    "    sanity_check += len(sub_df)\n",
    "    exp_target = np.array(target)[sub_df.index.to_list()]\n",
    "    exp_pred = np.squeeze(cagi_llr)[sub_df.index.to_list()]\n",
    "    exp_target = np.absolute(exp_target)\n",
    "    exp_pred = exp_pred\n",
    "    print(exp)\n",
    "    perf.append(stats.pearsonr(exp_pred,exp_target)[0])\n",
    "    print(stats.pearsonr(exp_pred,exp_target)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01159617285505605"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.01021866551181953\n",
    "np.mean(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {}\n",
    "idx = {'A':0,'C':1,'G':2,'T':3}\n",
    "for exp in exp_list:\n",
    "    exp_df = cagi_df[cagi_df['8']==exp]\n",
    "    idx_df = exp_df[['0','1','2']].drop_duplicates().sort_values(by=['1'])\n",
    "    exp_len = len(exp_df['1'].unique())\n",
    "    effect_size = np.zeros((4,exp_len))\n",
    "    predict_size = np.zeros((4,exp_len))\n",
    "    \n",
    "    for pos in range(0,exp_len):\n",
    "        row = idx_df.iloc[pos]\n",
    "        loci_df = exp_df[(exp_df['0']==row['0'])&(exp_df['1']==row['1'])&(exp_df['2']==row['2'])]\n",
    "        loci_idx = loci_df.index\n",
    "        ref_allele = loci_df['3'].drop_duplicates().values\n",
    "        alt_allele = loci_df['4'].values.tolist()\n",
    "        diff = loci_df['6'].values\n",
    "\n",
    "        effect_size[itemgetter(*alt_allele)(idx),pos] =np.absolute(diff)\n",
    "        #predict_size [itemgetter(*alt_allele)(idx),pos] =llr[loci_idx]\n",
    "        predict_size [itemgetter(*alt_allele)(idx),pos] =1\n",
    "    r_value = stats.pearsonr(effect_size.flatten(),predict_size.flatten())\n",
    "    performance_dict[exp]= r_value[0]\n",
    "    if plot_figure:\n",
    "        fig,ax = plt.subplots(2,1,figsize = (20,7))\n",
    "        #fig2=plt.figure(figsize = (20,2))\n",
    "        fig1 = sns.heatmap(effect_size,cmap = 'vlag',\n",
    "                            center = 0,\n",
    "                            #annot = exp_annot,fmt = '',\n",
    "                        cbar_kws = dict(use_gridspec=False,location=\"bottom\"),\n",
    "                        ax = ax[0]);\n",
    "        ax[0].tick_params(left=True, bottom=False);\n",
    "        #ax.set_yticklabels(['A','C','G','T'],size = 1);\n",
    "        ax[0].set_yticklabels([])\n",
    "        ax[0].set_xticklabels([]);\n",
    "        ax[0].set_title(exp+' ground truth')\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        #fig3=plt.figure(figsize = (20,2))\n",
    "        fig2 = sns.heatmap(predict_size,cmap = 'vlag',\n",
    "                            center = 0,\n",
    "                            #annot = pred_annot,fmt = '',\n",
    "                            cbar_kws = dict(use_gridspec=False,location=\"bottom\"),\n",
    "                            ax = ax[1]);\n",
    "        ax[1].tick_params(left=True, bottom=False);\n",
    "        #ax.set_yticklabels(['A','C','G','T'],size = 1);\n",
    "        ax[1].set_yticklabels([])\n",
    "        ax[1].set_xticklabels([])\n",
    "        ax[1].set_title(exp+' mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ZFAND3': 0.37958882258110616,\n",
       " 'HBG1': 0.3648951366719255,\n",
       " 'MSMB': 0.3939608936620037,\n",
       " 'LDLR': 0.2867844760793666,\n",
       " 'MYCrs6983267': 0.3637777785331868,\n",
       " 'SORT1': 0.3457491448088308,\n",
       " 'PKLR': 0.3535938034657003,\n",
       " 'F9': 0.40615243352173375,\n",
       " 'TERT-HEK293T': 0.40826779723051343,\n",
       " 'IRF6': 0.296117921725497,\n",
       " 'HBB': 0.4576562503479471,\n",
       " 'TERT-GBM': 0.3852918724452555,\n",
       " 'IRF4': 0.31538845447575753,\n",
       " 'GP1BB': 0.3248181791422176,\n",
       " 'HNF4A': 0.33819304988396887}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36128208964245495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(performance_dict.values())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare how different are the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "\n",
    "a_out = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/cagi_2B5_multi_species.h5','r')\n",
    "b_out = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/cagi_500M_human_ref.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagi_df = pd.read_csv('../../data/CAGI/final_cagi_metadata.csv',\n",
    "                      index_col=0).reset_index()\n",
    "exp_list = cagi_df['8'].unique()\n",
    "plot_figure=False\n",
    "a_out = a_out['llr'][()]\n",
    "b_out = b_out['llr'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {}\n",
    "alt_performance_dict = {}\n",
    "idx = {'A':0,'C':1,'G':2,'T':3}\n",
    "for exp in exp_list:\n",
    "    exp_df = cagi_df[cagi_df['8']==exp]\n",
    "    idx_df = exp_df[['0','1','2']].drop_duplicates().sort_values(by=['1'])\n",
    "    exp_len = len(exp_df['1'].unique())\n",
    "    effect_size = np.zeros((4,exp_len))\n",
    "    predict_size = np.zeros((4,exp_len))\n",
    "    alt_predict_size = np.zeros((4,exp_len))\n",
    "    \n",
    "    for pos in range(0,exp_len):\n",
    "        row = idx_df.iloc[pos]\n",
    "        loci_df = exp_df[(exp_df['0']==row['0'])&(exp_df['1']==row['1'])&(exp_df['2']==row['2'])]\n",
    "        loci_idx = loci_df.index\n",
    "        ref_allele = loci_df['3'].drop_duplicates().values\n",
    "        alt_allele = loci_df['4'].values.tolist()\n",
    "        diff = loci_df['6'].values\n",
    "\n",
    "        effect_size[itemgetter(*alt_allele)(idx),pos] =np.absolute(diff)\n",
    "        predict_size [itemgetter(*alt_allele)(idx),pos] =a_out[loci_idx]\n",
    "        alt_predict_size [itemgetter(*alt_allele)(idx),pos] =b_out[loci_idx]\n",
    "\n",
    "    r_value = stats.pearsonr(effect_size.flatten(),predict_size.flatten())\n",
    "    alt_r_value = stats.pearsonr(effect_size.flatten(),alt_predict_size.flatten())\n",
    "    performance_dict[exp]= r_value[0]\n",
    "    alt_performance_dict[exp]= alt_r_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99991727, 0.        , 0.99992973, ..., 0.        , 0.9999243 ,\n",
       "        0.99911875],\n",
       "       [0.        , 0.99928528, 0.99990278, ..., 0.99988973, 0.99988055,\n",
       "        0.        ],\n",
       "       [0.        , 0.99911839, 0.        , ..., 0.99970317, 0.        ,\n",
       "        0.99935865],\n",
       "       [0.        , 0.9999314 , 0.99993867, ..., 0.9999159 , 0.99987179,\n",
       "        0.9997077 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.2867984790769957, pvalue=1.3880290840794402e-25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(effect_size.flatten(),predict_size.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99982399, 0.        , 0.99986553, ..., 0.        , 0.99976522,\n",
       "        0.9996832 ],\n",
       "       [0.        , 0.99982858, 0.99980557, ..., 0.99964333, 0.99968797,\n",
       "        0.        ],\n",
       "       [0.        , 0.99987394, 0.        , ..., 0.99973935, 0.        ,\n",
       "        0.99973369],\n",
       "       [0.        , 0.99981195, 0.99978489, ..., 0.99969804, 0.99955088,\n",
       "        0.99979353]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_predict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.286789759083672, pvalue=1.3928977404317928e-25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(effect_size.flatten(),alt_predict_size.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-jk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "215fe59d3590bf3292bec95a1a0e8b527c92e76cc578acb0875ce70c209a23c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
