{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "sys.path.append('/home/ztang/multitask_RNA/data_generation')\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(\"/home/ztang/multitask_RNA/data/CAGI/230/CAGI_230_onehot.h5\", \"r\")\n",
    "alt = file['alt']\n",
    "ref = file['ref']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nucleotide Transformer zero shot test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine similarity between embeddings with different allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2B5_model\n"
     ]
    }
   ],
   "source": [
    "import nucleotide_transformer\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from nucleotide_transformer.pretrained import get_pretrained_model\n",
    "from tqdm import tqdm\n",
    "model_name = '2B5_multi_species'\n",
    "\n",
    "if '2B5' in model_name:\n",
    "    print('2B5_model')\n",
    "    embed_layer = 32\n",
    "else:\n",
    "    print('500M model')\n",
    "    embed_layer = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, forward_fn, tokenizer, config = get_pretrained_model(\n",
    "    model_name=model_name,\n",
    "    mixed_precision=False,\n",
    "    embeddings_layers_to_save=(embed_layer,),\n",
    "    attention_maps_to_save=(),\n",
    "    max_positions=513,\n",
    ")\n",
    "forward_fn = hk.transform(forward_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [29:30<00:00, 12.21s/it]\n"
     ]
    }
   ],
   "source": [
    "random_key = jax.random.PRNGKey(0)\n",
    "N, L, A = alt.shape\n",
    "mut_i = int(L/2-1)\n",
    "batch_size = 128\n",
    "cagi_llr=[]\n",
    "for i in tqdm(range(0,N,batch_size)):\n",
    "    b_size = 128\n",
    "    if i + batch_size > N:\n",
    "        b_size = N-batch_size\n",
    "    onehot = np.concatenate((ref[i:i+b_size],alt[i:i+b_size]))\n",
    "    seq = utils.onehot_to_seq(onehot)\n",
    "    token_out = tokenizer.batch_tokenize(seq)\n",
    "    token_id = [b[1] for b in token_out]\n",
    "    seq_pair = jnp.asarray(token_id,dtype=jnp.int32)\n",
    "    outs = forward_fn.apply(parameters, random_key, seq_pair)\n",
    "    for i in range(b_size):\n",
    "        ref_out = outs['embeddings_'+str(embed_layer)][i]\n",
    "        alt_out = outs['embeddings_'+str(embed_layer)][i+b_size]\n",
    "        cagi_llr.append((ref_out * alt_out).sum()/(jnp.linalg.norm(ref_out)*jnp.linalg.norm(alt_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/230/cagi_'+model_name+'.h5', 'w')\n",
    "output.create_dataset('llr', data=np.array(cagi_llr))\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats\n",
    "cagi_result = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/230/cagi_2B5_multi_species.h5', 'r')\n",
    "llr = cagi_result['llr'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagi_df = pd.read_csv('../../data/CAGI/230/final_cagi_metadata.csv',\n",
    "                      index_col=0).reset_index()\n",
    "exp_list = cagi_df['8'].unique()\n",
    "plot_figure=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {}\n",
    "idx = {'A':0,'C':1,'G':2,'T':3}\n",
    "for exp in exp_list:\n",
    "    exp_df = cagi_df[cagi_df['8']==exp]\n",
    "    idx_df = exp_df[['0','1','2']].drop_duplicates().sort_values(by=['1'])\n",
    "    exp_len = len(exp_df['1'].unique())\n",
    "    effect_size = np.zeros((4,exp_len))\n",
    "    predict_size = np.zeros((4,exp_len))\n",
    "    \n",
    "    for pos in range(0,exp_len):\n",
    "        row = idx_df.iloc[pos]\n",
    "        loci_df = exp_df[(exp_df['0']==row['0'])&(exp_df['1']==row['1'])&(exp_df['2']==row['2'])]\n",
    "        loci_idx = loci_df.index\n",
    "        ref_allele = loci_df['3'].drop_duplicates().values\n",
    "        alt_allele = loci_df['4'].values.tolist()\n",
    "        diff = loci_df['6'].values\n",
    "\n",
    "        effect_size[itemgetter(*alt_allele)(idx),pos] =np.absolute(diff)\n",
    "        #predict_size [itemgetter(*alt_allele)(idx),pos] =llr[loci_idx]\n",
    "        predict_size [itemgetter(*alt_allele)(idx),pos] =1\n",
    "    r_value = stats.pearsonr(effect_size.flatten(),predict_size.flatten())\n",
    "    performance_dict[exp]= r_value[0]\n",
    "    if plot_figure:\n",
    "        fig,ax = plt.subplots(2,1,figsize = (20,7))\n",
    "        #fig2=plt.figure(figsize = (20,2))\n",
    "        fig1 = sns.heatmap(effect_size,cmap = 'vlag',\n",
    "                            center = 0,\n",
    "                            #annot = exp_annot,fmt = '',\n",
    "                        cbar_kws = dict(use_gridspec=False,location=\"bottom\"),\n",
    "                        ax = ax[0]);\n",
    "        ax[0].tick_params(left=True, bottom=False);\n",
    "        #ax.set_yticklabels(['A','C','G','T'],size = 1);\n",
    "        ax[0].set_yticklabels([])\n",
    "        ax[0].set_xticklabels([]);\n",
    "        ax[0].set_title(exp+' ground truth')\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        #fig3=plt.figure(figsize = (20,2))\n",
    "        fig2 = sns.heatmap(predict_size,cmap = 'vlag',\n",
    "                            center = 0,\n",
    "                            #annot = pred_annot,fmt = '',\n",
    "                            cbar_kws = dict(use_gridspec=False,location=\"bottom\"),\n",
    "                            ax = ax[1]);\n",
    "        ax[1].tick_params(left=True, bottom=False);\n",
    "        #ax.set_yticklabels(['A','C','G','T'],size = 1);\n",
    "        ax[1].set_yticklabels([])\n",
    "        ax[1].set_xticklabels([])\n",
    "        ax[1].set_title(exp+' mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ZFAND3': 0.37958882258110616,\n",
       " 'HBG1': 0.3648951366719255,\n",
       " 'MSMB': 0.3939608936620037,\n",
       " 'LDLR': 0.2867844760793666,\n",
       " 'MYCrs6983267': 0.3637777785331868,\n",
       " 'SORT1': 0.3457491448088308,\n",
       " 'PKLR': 0.3535938034657003,\n",
       " 'F9': 0.40615243352173375,\n",
       " 'TERT-HEK293T': 0.40826779723051343,\n",
       " 'IRF6': 0.296117921725497,\n",
       " 'HBB': 0.4576562503479471,\n",
       " 'TERT-GBM': 0.3852918724452555,\n",
       " 'IRF4': 0.31538845447575753,\n",
       " 'GP1BB': 0.3248181791422176,\n",
       " 'HNF4A': 0.33819304988396887}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36128208964245495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(performance_dict.values())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare how different are the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "\n",
    "a_out = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/cagi_2B5_multi_species.h5','r')\n",
    "b_out = h5py.File('/home/ztang/multitask_RNA/data/CAGI/zero_shot/cagi_500M_human_ref.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagi_df = pd.read_csv('../../data/CAGI/final_cagi_metadata.csv',\n",
    "                      index_col=0).reset_index()\n",
    "exp_list = cagi_df['8'].unique()\n",
    "plot_figure=False\n",
    "a_out = a_out['llr'][()]\n",
    "b_out = b_out['llr'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {}\n",
    "alt_performance_dict = {}\n",
    "idx = {'A':0,'C':1,'G':2,'T':3}\n",
    "for exp in exp_list:\n",
    "    exp_df = cagi_df[cagi_df['8']==exp]\n",
    "    idx_df = exp_df[['0','1','2']].drop_duplicates().sort_values(by=['1'])\n",
    "    exp_len = len(exp_df['1'].unique())\n",
    "    effect_size = np.zeros((4,exp_len))\n",
    "    predict_size = np.zeros((4,exp_len))\n",
    "    alt_predict_size = np.zeros((4,exp_len))\n",
    "    \n",
    "    for pos in range(0,exp_len):\n",
    "        row = idx_df.iloc[pos]\n",
    "        loci_df = exp_df[(exp_df['0']==row['0'])&(exp_df['1']==row['1'])&(exp_df['2']==row['2'])]\n",
    "        loci_idx = loci_df.index\n",
    "        ref_allele = loci_df['3'].drop_duplicates().values\n",
    "        alt_allele = loci_df['4'].values.tolist()\n",
    "        diff = loci_df['6'].values\n",
    "\n",
    "        effect_size[itemgetter(*alt_allele)(idx),pos] =np.absolute(diff)\n",
    "        predict_size [itemgetter(*alt_allele)(idx),pos] =a_out[loci_idx]\n",
    "        alt_predict_size [itemgetter(*alt_allele)(idx),pos] =b_out[loci_idx]\n",
    "\n",
    "    r_value = stats.pearsonr(effect_size.flatten(),predict_size.flatten())\n",
    "    alt_r_value = stats.pearsonr(effect_size.flatten(),alt_predict_size.flatten())\n",
    "    performance_dict[exp]= r_value[0]\n",
    "    alt_performance_dict[exp]= alt_r_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99991727, 0.        , 0.99992973, ..., 0.        , 0.9999243 ,\n",
       "        0.99911875],\n",
       "       [0.        , 0.99928528, 0.99990278, ..., 0.99988973, 0.99988055,\n",
       "        0.        ],\n",
       "       [0.        , 0.99911839, 0.        , ..., 0.99970317, 0.        ,\n",
       "        0.99935865],\n",
       "       [0.        , 0.9999314 , 0.99993867, ..., 0.9999159 , 0.99987179,\n",
       "        0.9997077 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.2867984790769957, pvalue=1.3880290840794402e-25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(effect_size.flatten(),predict_size.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99982399, 0.        , 0.99986553, ..., 0.        , 0.99976522,\n",
       "        0.9996832 ],\n",
       "       [0.        , 0.99982858, 0.99980557, ..., 0.99964333, 0.99968797,\n",
       "        0.        ],\n",
       "       [0.        , 0.99987394, 0.        , ..., 0.99973935, 0.        ,\n",
       "        0.99973369],\n",
       "       [0.        , 0.99981195, 0.99978489, ..., 0.99969804, 0.99955088,\n",
       "        0.99979353]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_predict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.286789759083672, pvalue=1.3928977404317928e-25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(effect_size.flatten(),alt_predict_size.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-jk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "215fe59d3590bf3292bec95a1a0e8b527c92e76cc578acb0875ce70c209a23c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
