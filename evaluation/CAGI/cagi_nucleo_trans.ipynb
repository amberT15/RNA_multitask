{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "sys.path.append('/home/amber/multitask_RNA/data_generation')\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(\"/home/amber/multitask_RNA/data/CAGI/CAGI_onehot.h5\", \"r\")\n",
    "alt = file['alt']\n",
    "ref = file['ref']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nucleotide Transformer zero shot test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine similarity between embeddings with different allele√ü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nucleotide_transformer\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from nucleotide_transformer.pretrained import get_pretrained_model\n",
    "from tqdm import tqdm\n",
    "model_name = '500M_1000G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, forward_fn, tokenizer, config = get_pretrained_model(\n",
    "    model_name=model_name,\n",
    "    mixed_precision=False,\n",
    "    embeddings_layers_to_save=(24,),\n",
    "    attention_maps_to_save=(),\n",
    "    max_positions=513,\n",
    ")\n",
    "forward_fn = hk.transform(forward_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/18442 [00:08<10:52:03,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "random_key = jax.random.PRNGKey(0)\n",
    "N, L, A = alt.shape\n",
    "mut_i = int(L/2-1)\n",
    "cagi_llr=[]\n",
    "for i in tqdm(range(N)):\n",
    "    seq = utils.onehot_to_seq([ref[i],alt[i]])\n",
    "    token_out = tokenizer.batch_tokenize(seq)\n",
    "    token_id = [b[1] for b in token_out]\n",
    "    seq_pair = jnp.asarray(token_id,dtype=jnp.int32)\n",
    "    outs = forward_fn.apply(parameters, random_key, seq_pair)\n",
    "    ref_seq = outs['embeddings_24'][0]\n",
    "    alt_seq = outs['embeddings_24'][1]\n",
    "    #cosine similarity\n",
    "    cagi_llr.append((ref_seq * alt_seq).sum()/(jnp.linalg.norm(ref_seq)*jnp.linalg.norm(alt_seq)))\n",
    "    if i == 4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.999932, dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ref_seq * alt_seq).sum()/(jnp.linalg.norm(ref_seq)*jnp.linalg.norm(alt_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array(0.99993193, dtype=float32),\n",
       " Array(0.9999533, dtype=float32),\n",
       " Array(0.999915, dtype=float32),\n",
       " Array(0.9998209, dtype=float32),\n",
       " Array(0.999932, dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cagi_llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = h5py.File('./cagi_nuc_trans.h5', 'w')\n",
    "output.create_dataset('llr', data=np.array(cagi_llr))\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats\n",
    "cagi_result = h5py.File('./cagi_nuc_trans.h5', 'r')\n",
    "llr = cagi_result['llr'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagi_df = pd.read_csv('../../data/CAGI/final_cagi_metadata.csv',\n",
    "                      index_col=0).reset_index()\n",
    "exp_list = cagi_df['8'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBB PearsonRResult(statistic=-0.07143840082210977, pvalue=0.05019814686141383)\n",
      "SORT1 PearsonRResult(statistic=-0.1250315620738263, pvalue=7.93553954826849e-10)\n",
      "TERT-GBM PearsonRResult(statistic=-0.10991958288763477, pvalue=0.0003934323553775421)\n",
      "PKLR PearsonRResult(statistic=-0.09535978811016381, pvalue=3.3862694687910185e-05)\n",
      "MYCrs6983267 PearsonRResult(statistic=-0.01970531618485258, pvalue=0.3345697699151188)\n",
      "IRF6 PearsonRResult(statistic=-0.06966600585094972, pvalue=0.000623939415715905)\n",
      "MSMB PearsonRResult(statistic=-0.009039657568562454, pvalue=0.6604488434212695)\n",
      "HBG1 PearsonRResult(statistic=-0.18923372414902623, pvalue=2.7061538697255745e-10)\n",
      "TERT-HEK293T PearsonRResult(statistic=-0.13154088672959968, pvalue=2.1640386808471713e-05)\n",
      "F9 PearsonRResult(statistic=-0.009370378036635674, pvalue=0.7445083953867795)\n",
      "ZFAND3 PearsonRResult(statistic=-0.08329519414236096, pvalue=5.985560870741031e-05)\n",
      "HNF4A PearsonRResult(statistic=-0.006000024131395117, pvalue=0.8396323978238834)\n",
      "IRF4 PearsonRResult(statistic=-0.13615197994361894, pvalue=6.402098784722258e-09)\n",
      "GP1BB PearsonRResult(statistic=-0.1470777148329757, pvalue=6.3922518050692576e-09)\n",
      "LDLR PearsonRResult(statistic=-0.18372668614514195, pvalue=3.769563587616078e-11)\n"
     ]
    }
   ],
   "source": [
    "idx = {'A':0,'C':1,'G':2,'T':3}\n",
    "for exp in exp_list:\n",
    "    exp_df = cagi_df[cagi_df['8']==exp]\n",
    "    idx_df = exp_df[['0','1','2']].drop_duplicates().sort_values(by=['1'])\n",
    "    exp_len = len(exp_df['1'].unique())\n",
    "    effect_size = np.zeros((4,exp_len))\n",
    "    predict_size = np.zeros((4,exp_len))\n",
    "    \n",
    "    for pos in range(0,exp_len):\n",
    "        row = idx_df.iloc[pos]\n",
    "        loci_df = exp_df[(exp_df['0']==row['0'])&(exp_df['1']==row['1'])&(exp_df['2']==row['2'])]\n",
    "        loci_idx = loci_df.index\n",
    "        ref_allele = loci_df['3'].drop_duplicates().values\n",
    "        alt_allele = loci_df['4'].values.tolist()\n",
    "        diff = loci_df['6'].values\n",
    "\n",
    "        effect_size[itemgetter(*alt_allele)(idx),pos] =diff\n",
    "        predict_size [itemgetter(*alt_allele)(idx),pos] =llr[loci_idx]\n",
    "    #slope, intercept, r_value, p_value, std_err = stats.linregress(effect_size.flatten(),predict_size.flatten())\n",
    "    #print(exp,r_value)\n",
    "    r_value = stats.pearsonr(effect_size.flatten(),predict_size.flatten())\n",
    "    print(exp,r_value[0])\n",
    "    # fig,ax = plt.subplots(2,1,figsize = (20,7))\n",
    "    # #fig2=plt.figure(figsize = (20,2))\n",
    "    # fig1 = sns.heatmap(effect_size,cmap = 'vlag',\n",
    "    #                     center = 0,\n",
    "    #                     #annot = exp_annot,fmt = '',\n",
    "    #                 cbar_kws = dict(use_gridspec=False,location=\"bottom\"),\n",
    "    #                 ax = ax[0]);\n",
    "    # ax[0].tick_params(left=True, bottom=False);\n",
    "    # #ax.set_yticklabels(['A','C','G','T'],size = 1);\n",
    "    # ax[0].set_yticklabels([])\n",
    "    # ax[0].set_xticklabels([]);\n",
    "    # ax[0].set_title(exp+' ground truth')\n",
    "    # #plt.tight_layout()\n",
    "\n",
    "    # #fig3=plt.figure(figsize = (20,2))\n",
    "    # fig2 = sns.heatmap(predict_size,cmap = 'vlag',\n",
    "    #                     center = 0,\n",
    "    #                     #annot = pred_annot,fmt = '',\n",
    "    #                     cbar_kws = dict(use_gridspec=False,location=\"bottom\"),\n",
    "    #                     ax = ax[1]);\n",
    "    # ax[1].tick_params(left=True, bottom=False);\n",
    "    # #ax.set_yticklabels(['A','C','G','T'],size = 1);\n",
    "    # ax[1].set_yticklabels([])\n",
    "    # ax[1].set_xticklabels([])\n",
    "    # ax[1].set_title(exp+' mutagenesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18372668614514207"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-jk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "215fe59d3590bf3292bec95a1a0e8b527c92e76cc578acb0875ce70c209a23c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
