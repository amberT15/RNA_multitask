{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/amber/multitask_RNA/replications/GPN/GPN_archive/checkpoint-80000 were not used when initializing ConvNetModel: ['cls.decoder.3.weight', 'cls.decoder.0.weight', 'cls.decoder.2.bias', 'cls.decoder.3.bias', 'cls.decoder.2.weight', 'cls.decoder.0.bias']\n",
      "- This IS expected if you are initializing ConvNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ConvNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "from Bio import SeqIO\n",
    "import bioframe\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import h5py\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from transformers import AutoModel,AutoTokenizer,AutoModelForMaskedLM\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gpn.mlm\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "#gonzalobenegas/gpn-arabidopsis\n",
    "#model = AutoModel.from_pretrained(\"/home/amber/multitask_RNA/replications/GPN/GPN_finetune/checkpoint-2000000\").to('cuda')\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"/home/amber/multitask_RNA/replications/GPN/GPN_finetune/checkpoint-2000000\")\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"gonzalobenegas/gpn-arabidopsis\").to('cuda')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gonzalobenegas/gpn-arabidopsis\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"/home/amber/multitask_RNA/replications/GPN/GPN_archive/checkpoint-80000\").to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/amber/multitask_RNA/replications/GPN/GPN_archive/checkpoint-80000\")\n",
    "\n",
    "model.eval();\n",
    "file = h5py.File('../../data/rna_stable/insert_dataset.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:05<00:00,  6.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 286/286 [00:46<00:00,  6.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:05<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "gpn_output = h5py.File('../../data/rna_stable/gpn_human_embed.h5','w')\n",
    "batch_size = 32\n",
    "for dataset in ['test','train','valid']:\n",
    "    key = 'X_'+dataset\n",
    "    onehot = file[key]\n",
    "    string_seq = utils.onehot_to_seq(onehot)\n",
    "\n",
    "    token_seq = tokenizer.batch_encode_plus(string_seq, max_length=512,padding = 'max_length')\n",
    "    output_cache = []\n",
    "    for seq_i in tqdm(range(0,len(token_seq['input_ids']),batch_size)):\n",
    "        seq_batch = torch.tensor(token_seq['input_ids'][seq_i:seq_i+batch_size]).to('cuda')\n",
    "        output_seq = model(seq_batch).last_hidden_state.cpu().detach().numpy()\n",
    "        output_cache.extend(output_seq[:,:173,:])\n",
    "    gpn_output.create_dataset(name=key,data = np.array(output_cache))\n",
    "    gpn_output.create_dataset(name='Y_'+dataset,data = file['Y_'+dataset][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpn_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 173, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(output_cache).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e8284e1417b754e460c2bde3a4a4837c482fa82ceb7d52f4acbe340dd4b4559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
