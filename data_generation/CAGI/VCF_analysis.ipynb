{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "import numpy as np\n",
    "import os, h5py\n",
    "import pandas as pd\n",
    "from gopher import variant_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read df and add strand\n",
    "all_dfs = []\n",
    "cagi_data = '../../data/CAGI/raw/'\n",
    "combined_filename = '../../data/CAGI/combined_cagi.bed'\n",
    "for filename in os.listdir(cagi_data):\n",
    "    prefix, regulator = filename.split('.tsv')[0].split('_')\n",
    "\n",
    "    one_reg = pd.read_csv(os.path.join(cagi_data,filename), skiprows=7, sep='\\t', header=None)\n",
    "    one_reg['regulator'] = regulator\n",
    "    one_reg['set'] = prefix\n",
    "    all_dfs.append(one_reg)\n",
    "    \n",
    "\n",
    "combined_cagi = pd.concat(all_dfs)\n",
    "combined_cagi.insert(4, 'strand', '+')\n",
    "combined_cagi.insert(2,'end',combined_cagi.iloc[:,1]+1)\n",
    "combined_cagi.iloc[:,0] = 'chr'+combined_cagi.iloc[:,0].astype(str)\n",
    "combined_cagi.to_csv(combined_filename, sep='\\t', header=False, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = '../data/nonneg_cagi_3K.bed'\n",
    "variant_effect.expand_range(combined_filename, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_filename = '../data/cagi_3k.fa'\n",
    "coords_list, seqs_list = variant_effect.convert_bed_to_seq(output_filename, fa_filename, genomefile='/home/shush/genomes/hg19.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3072\n",
    "bad_lines = []\n",
    "N = len(seqs_list)\n",
    "nonneg_df = pd.read_csv(output_filename, sep='\\t', header=None)\n",
    "mid = window // 2\n",
    "onehot_ref = []\n",
    "onehot_alt = []\n",
    "coord_np = np.empty((N, 4)) # chrom, start, end coordinate array\n",
    "pos_dict = {'+': 1535, '-':1536}\n",
    "for i,(chr_s_e, seq) in enumerate(zip(coords_list, seqs_list)):\n",
    "    alt = ''\n",
    "    strand = chr_s_e.split('(')[-1].split(')')[0]\n",
    "    pos = pos_dict[strand]\n",
    "#     coord_np[i,3] = pos_dict[strand] - 1535\n",
    "\n",
    "    if seq[pos] != nonneg_df.iloc[i, 3]:\n",
    "#         print('Error in line ' + str(i))\n",
    "        bad_lines.append(i)\n",
    "    else:\n",
    "        alt = nonneg_df.iloc[i,4]\n",
    "\n",
    "        onehot = variant_effect.dna_one_hot(seq)\n",
    "        mutated_onehot = onehot.copy()\n",
    "        mutated_onehot[pos] = variant_effect.dna_one_hot(alt)[0]\n",
    "        onehot_ref.append(onehot)\n",
    "\n",
    "        onehot_alt.append(mutated_onehot) \n",
    "\n",
    "onehot_alt = np.array(onehot_alt)\n",
    "onehot_ref = np.array(onehot_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_df = nonneg_df[~nonneg_df.index.isin(bad_lines)]\n",
    "included_df.to_csv('../data/final_cagi_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_ref_alt = h5py.File('../data/CAGI_onehot.h5', 'w')\n",
    "onehot_ref_alt.create_dataset('ref', data=onehot_ref)\n",
    "onehot_ref_alt.create_dataset('alt', data=onehot_alt)\n",
    "onehot_ref_alt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sanity check that only one nucleotide is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1535,    0],\n",
       "       [1535,    1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_ref_alt = h5py.File('../data/CAGI_onehot.h5', 'r')\n",
    "np.argwhere(onehot_ref_alt['ref'][0,:,:] != onehot_ref_alt['alt'][0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0., 0.], dtype=float16),\n",
       " array([1., 0., 0., 0.], dtype=float16))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_ref_alt['ref'][0,1535,:], onehot_ref_alt['alt'][0,1535,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run functional variant calling with eixisting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in created dataset\n",
    "onehot_ref_alt = h5py.File('../data/CAGI_onehot.h5', 'r')\n",
    "ref = onehot_ref_alt['ref'][()]\n",
    "alt = onehot_ref_alt['alt'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18442, 3072, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 18:36:53.738143: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-17 18:36:54.284081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n",
      "2022-03-17 18:36:55.637068: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-03-17 18:36:57.175156: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Quantiative model\n",
    "import variant_effect\n",
    "variant_effect.vcf_quantitative('../tutorial_outputs/',ref,alt,2048,\n",
    "                                '../data/cagi_robust',robust = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary model\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "variant_effect.vcf_binary('../tutorial_binary/files/best_model.h5',ref,alt,-1,2048,\n",
    "                               '../data/cagi_binary_robust',robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
