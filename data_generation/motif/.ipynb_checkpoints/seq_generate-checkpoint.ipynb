{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "organism = 'plants'\n",
    "#np.random.seed(22) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process JASPAR pfm and convert to pwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVERSE_VOCAB = np.array(['A','C','G','T','N'])\n",
    "def onehot_to_seq(onehot_array):\n",
    "    seq_array = []\n",
    "    for onehot in onehot_array:\n",
    "        adj = np.sum(onehot, axis=-2) == 0\n",
    "        x_index = np.argmax(onehot,axis=-2) - adj\n",
    "        seq_onehot = REVERSE_VOCAB[x_index]\n",
    "        seq_char = ''.join(seq_onehot)\n",
    "        seq_array.append(seq_char)\n",
    "    return np.array(seq_array)\n",
    "\n",
    "\n",
    "def list_duplicates(seq):\n",
    "    tally = defaultdict(list)\n",
    "    for i,item in enumerate(seq):\n",
    "        tally[item].append(i)\n",
    "    return ((key,locs) for key,locs in tally.items() \n",
    "                            if len(locs)>1)\n",
    "\n",
    "def get_jaspar_motifs(file_path):\n",
    "    def get_motif(f):\n",
    "        line = f.readline()\n",
    "        name = line.strip().split()[1]\n",
    "        pfm = []\n",
    "        for i in range(4):\n",
    "            line = f.readline()\n",
    "            if len(line.split()[1]) > 1:\n",
    "                pfm.append(np.asarray(np.hstack([line.split()[1][1:], line.split()[2:-1]]), dtype=float))\n",
    "            else:\n",
    "                pfm.append(np.asarray(line.split()[2:-1], dtype=float))\n",
    "        pfm = np.vstack(pfm)\n",
    "        sum_pfm = np.sum(pfm, axis=0)\n",
    "        pwm = pfm/np.outer(np.ones(4), sum_pfm)\n",
    "        return name, pwm\n",
    "\n",
    "    num_lines = sum(1 for line in open(file_path))\n",
    "    num_motifs = int(num_lines/5)\n",
    "\n",
    "    f = open(file_path)\n",
    "    tf_names = []\n",
    "    tf_motifs = []\n",
    "    for i in range(num_motifs):\n",
    "        name, pwm = get_motif(f)\n",
    "        tf_names.append(name)\n",
    "        tf_motifs.append(pwm)\n",
    "\n",
    "    return tf_motifs, tf_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse JASPAR motifs\n",
    "savepath = '/home/amber/multitask_RNA/data/motif/'+organism+'/'\n",
    "file_path = os.path.join(savepath, 'pfm_'+organism+'.txt')\n",
    "motif_set, motif_names = get_jaspar_motifs(file_path)\n",
    "total_index = np.arange(len(motif_set))\n",
    "\n",
    "#remove duplicates\n",
    "dup_index = []\n",
    "dup_index = [dup[-1][-1] for dup in list_duplicates(motif_names)]\n",
    "unique_index = set(total_index) - set(dup_index)\n",
    "\n",
    "# get a subset of core motifs\n",
    "if organism == 'plants':\n",
    "     core_names = ['TRB1','TRB2']\n",
    "elif organism == 'vertebrates':\n",
    "    core_names = ['SP1', 'GABPA', 'CEBPB', 'MAX', 'Yy1']\n",
    "\n",
    "strand_motifs = []\n",
    "for name in core_names:\n",
    "    index = motif_names.index(name)\n",
    "    unique_index.remove(index)\n",
    "    strand_motifs.append(motif_set[index])\n",
    "#========================================================\n",
    "# #or pure random selection\n",
    "# core_names=[]\n",
    "# strand_motifs=[]\n",
    "\n",
    "# randomly select more motifs\n",
    "num_background = 95        \n",
    "motif_index = np.random.choice(list(unique_index),num_background,replace=False)\n",
    "core_names.extend(np.array(motif_names)[motif_index])\n",
    "for index in motif_index:\n",
    "    pwm = motif_set[index]\n",
    "    strand_motifs.append(pwm)  \n",
    "\n",
    "# generate reverse compliments\n",
    "core_motifs = []\n",
    "for pwm in strand_motifs:\n",
    "    core_motifs.append(pwm)\n",
    "    reverse = pwm[:,::-1]\n",
    "    core_motifs.append(reverse[::-1,:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation to creat sequence with motif embed (Full random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_seq(motifs,seq_length,rep_num,center=False):\n",
    "\n",
    "    def per_motif_insertion(motif,seq_length,rep_num,center = False):\n",
    "        motif_len = motif.shape[1]\n",
    "        seq_pwm = np.ones((rep_num,4,seq_length))/4\n",
    "        if center == False:\n",
    "            loci = np.random.randint(0,seq_length-motif.shape[1],rep_num)\n",
    "        elif center == True:\n",
    "            loci = np.full(rep_num, int((seq_length-motif.shape[1])/2))\n",
    "        else:\n",
    "            raise ValueError('Enter boolean value for center field.')\n",
    "        location = []\n",
    "        for i in range(len(loci)):\n",
    "            seq_pwm[i,:,loci[i]:loci[i]+motif_len] = motif\n",
    "            location.append(np.arange(loci[i],loci[i]+motif_len))    \n",
    "\n",
    "        Z = np.random.uniform(0,1,(rep_num,seq_length))\n",
    "        cum_prob = seq_pwm.cumsum(axis=1)\n",
    "        one_hot_seq = np.zeros(seq_pwm.shape)\n",
    "        for i in range(rep_num):\n",
    "            for j in range(seq_length):\n",
    "                index=[k for k in range(4) if Z[i,j] < cum_prob[i,k,j]][0]\n",
    "                one_hot_seq[i,index,j] = 1\n",
    "        return one_hot_seq, np.array(location)\n",
    "\n",
    "    sequence = []\n",
    "    insert_loci = []\n",
    "    for motif in motifs:\n",
    "        seq,loci, =  per_motif_insertion(motif,seq_length,rep_num,center=center)\n",
    "        sequence.append(onehot_to_seq(seq))\n",
    "        insert_loci.append(loci)\n",
    "        \n",
    "    return np.array(sequence),insert_loci\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_seq,loci = generate_seq(core_motifs,512,50,center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('/home/amber/multitask_RNA/data/motif/plants/random_center/synthetic_seq.h5','w')\n",
    "for i in range(len(core_names)):\n",
    "    file.create_dataset(core_names[i],data = np.hstack([onehot_seq[2*i],onehot_seq[2*i+1]]).tolist())\n",
    "    file.create_dataset(core_names[i]+'_loci',data = np.vstack([loci[2*i],loci[2*i+1]]).tolist())\n",
    "file.close()\n",
    "\n",
    "with open('/home/amber/multitask_RNA/data/motif/plants/random_center/selected_motif.csv', 'w') as fp:\n",
    "    for item in core_names:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Di-nuc shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gopher.dinuc_shuffle import dinuc_shuffle\n",
    "from gopher.variant_effect import dna_one_hot\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-27cf6341afd1f923\n",
      "Found cached dataset parquet (/home/amber/.cache/huggingface/datasets/parquet/default-27cf6341afd1f923/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa66124561754fbc8742ea9c90d47cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rep_per_motif=100\n",
    "data_files={}\n",
    "data_files[\"test\"] ='/home/amber/multitask_RNA/data/GPN_plant/dataset/test/Arabidopsis_thaliana.test.512.256.parquet'\n",
    "extension = 'parquet'\n",
    "raw_datasets = load_dataset(extension, data_files=data_files, cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_len = [i.shape[-1] for i in core_motifs]\n",
    "max_motif_len = max(motif_len)\n",
    "background_seq_index = np.random.choice(len(raw_datasets['test']),rep_per_motif)\n",
    "background_seq = np.array(raw_datasets['test']['seq'])[background_seq_index]\n",
    "background_onehot = np.array([dna_one_hot(seq) for seq in background_seq])\n",
    "shuffle_onehot = np.array([dinuc_shuffle(onehot) for onehot in background_onehot])\n",
    "shuffle_onehot = np.swapaxes(shuffle_onehot,1,2)\n",
    "insert_loci = np.random.choice(background_onehot.shape[1]-max_motif_len,rep_per_motif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('/home/amber/multitask_RNA/data/motif/plants/dinuc_shuffle/synthetic_seq.h5','w')\n",
    "for i in range(len(core_names)):\n",
    "    motifs = [core_motifs[2*i],core_motifs[2*i+1]]\n",
    "    motif_len = motifs[0].shape[-1]\n",
    "    location = []\n",
    "    seq = [] \n",
    "    for motif_pwm in motifs:\n",
    "        insert_seq = shuffle_onehot.copy()\n",
    "        cum_prob = motif_pwm.cumsum(axis=0)\n",
    "        Z = np.random.uniform(0,1,(rep_per_motif,motif_len))\n",
    "        for j,loci in enumerate(insert_loci):\n",
    "            motif = np.zeros(motif_pwm.shape)\n",
    "            for k in range(motif_len):\n",
    "                index = [base for base in range(4) if Z[j,k] < cum_prob[base,k]][0]\n",
    "                motif[index,k] = 1\n",
    "            insert_seq[j,:,loci:loci+motif_len] = motif\n",
    "            location.append(np.arange(loci,loci+motif_len))\n",
    "        seq.extend(onehot_to_seq(insert_seq))\n",
    "    file.create_dataset(core_names[i],data = np.array(seq).tolist())\n",
    "    file.create_dataset(core_names[i]+'_loci',data = location)\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/amber/multitask_RNA/data/motif/plants/dinuc_shuffle/selected_motif.csv', 'w') as fp:\n",
    "    for item in core_names:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw sequence insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gopher.dinuc_shuffle import dinuc_shuffle\n",
    "from gopher.variant_effect import dna_one_hot\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-27cf6341afd1f923\n",
      "Found cached dataset parquet (/home/amber/.cache/huggingface/datasets/parquet/default-27cf6341afd1f923/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338bada7c624438e9e87b4c6c81c3c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rep_per_motif=100\n",
    "data_files={}\n",
    "data_files[\"test\"] ='/home/amber/multitask_RNA/data/GPN_plant/dataset/test/Arabidopsis_thaliana.test.512.256.parquet'\n",
    "extension = 'parquet'\n",
    "raw_datasets = load_dataset(extension, data_files=data_files, cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_len = [i.shape[-1] for i in core_motifs]\n",
    "max_motif_len = max(motif_len)\n",
    "background_seq_index = np.random.choice(len(raw_datasets['test']),rep_per_motif)\n",
    "background_seq = np.array(raw_datasets['test']['seq'])[background_seq_index]\n",
    "background_onehot = np.array([dna_one_hot(seq) for seq in background_seq])\n",
    "background_onehot = np.swapaxes(background_onehot,1,2)\n",
    "insert_loci = np.random.choice(background_onehot.shape[-1]-max_motif_len,rep_per_motif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('/home/amber/multitask_RNA/data/motif/plants/raw_sequence/synthetic_seq.h5','w')\n",
    "for i in range(len(core_names)):\n",
    "    motifs = [core_motifs[2*i],core_motifs[2*i+1]]\n",
    "    motif_len = motifs[0].shape[-1]\n",
    "    location = []\n",
    "    seq = [] \n",
    "    for motif_pwm in motifs:\n",
    "        insert_seq = background_onehot.copy()\n",
    "        cum_prob = motif_pwm.cumsum(axis=0)\n",
    "        Z = np.random.uniform(0,1,(rep_per_motif,motif_len))\n",
    "        for j,loci in enumerate(insert_loci):\n",
    "            motif = np.zeros(motif_pwm.shape)\n",
    "            for k in range(motif_len):\n",
    "                index = [base for base in range(4) if Z[j,k] < cum_prob[base,k]][0]\n",
    "                motif[index,k] = 1\n",
    "            insert_seq[j,:,loci:loci+motif_len] = motif\n",
    "            location.append(np.arange(loci,loci+motif_len))\n",
    "        seq.extend(onehot_to_seq(insert_seq))\n",
    "    file.create_dataset(core_names[i],data = np.array(seq).tolist())\n",
    "    file.create_dataset(core_names[i]+'_loci',data = location)\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/amber/multitask_RNA/data/motif/plants/raw_sequence/selected_motif.csv', 'w') as fp:\n",
    "    for item in core_names:\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e8284e1417b754e460c2bde3a4a4837c482fa82ceb7d52f4acbe340dd4b4559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
