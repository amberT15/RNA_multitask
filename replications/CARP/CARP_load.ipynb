{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sequence_models.collaters import  MLMCollater\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sequence_models.constants import SPECIALS\n",
    "import carp_models\n",
    "sys.path.append('/home/amber/multitask_RNA/rna_self_train/')\n",
    "from dna_tokenizer import DNATokenizer,carp_maskwrapper\n",
    "import rna_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DNATokenizer('/home/amber/multitask_RNA/rna_self_train/vocab.txt')\n",
    "decay_rate = 0.15\n",
    "len_vocab = 4101\n",
    "padding_idx = tokenizer.pad_token_id\n",
    "data_dir = '/home/amber/multitask_RNA/data/pre-train/6mer/rna_seq.h5'\n",
    "train_data = rna_model.rna_kmer(data_dir,'train',6,tokenizer)\n",
    "valid_data = rna_model.rna_kmer(data_dir,'valid',6,tokenizer)\n",
    "collater = carp_maskwrapper(tokenizer,decay_rate,extend = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA='ACGTN'\n",
    "RNA_ALPHABET = RNA+SPECIALS\n",
    "len_vocab = len(RNA_ALPHABET)\n",
    "padding_idx = RNA_ALPHABET.index('-')\n",
    "train_data = carp_models.rna_self_mask('/home/amber/multitask_RNA/data/pre-train/context/rna_seq.h5','train')\n",
    "valid_data = carp_models.rna_self_mask('/home/amber/multitask_RNA/data/pre-train/context/rna_seq.h5','valid')\n",
    "collater = MLMCollater(RNA_ALPHABET,True,False,mut_alphabet=RNA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_data, num_workers=4,collate_fn = collater,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[3, 1, 0,  ..., 3, 7, 0],\n",
      "        [2, 2, 0,  ..., 1, 1, 0],\n",
      "        [2, 0, 1,  ..., 0, 2, 7],\n",
      "        ...,\n",
      "        [0, 2, 0,  ..., 0, 1, 1],\n",
      "        [0, 2, 0,  ..., 2, 0, 1],\n",
      "        [2, 1, 0,  ..., 2, 1, 3]]), tensor([[3, 1, 0,  ..., 3, 2, 0],\n",
      "        [2, 2, 0,  ..., 1, 1, 0],\n",
      "        [2, 0, 1,  ..., 0, 2, 3],\n",
      "        ...,\n",
      "        [0, 2, 0,  ..., 0, 1, 1],\n",
      "        [0, 2, 0,  ..., 2, 0, 1],\n",
      "        [2, 1, 0,  ..., 2, 1, 3]]), tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "for i in valid_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amber/multitask_RNA/replications/CARP/CARP_load.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/replications/CARP/CARP_load.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m./protein_model/carp_76M.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.load('./protein_model/carp_76M.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByteNetLM(\n",
       "  (embedder): ByteNet(\n",
       "    (embedder): Embedding(30, 8, padding_idx=6)\n",
       "    (up_embedder): PositionFeedForward(\n",
       "      (conv): Conv1d(8, 1024, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(16,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(64,), dilation=(32,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(128,), dilation=(64,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(256,), dilation=(128,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(16,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(64,), dilation=(32,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(128,), dilation=(64,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(256,), dilation=(128,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(16,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(64,), dilation=(32,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(128,), dilation=(64,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(256,), dilation=(128,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (24): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (25): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (26): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (27): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (28): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(16,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (29): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(64,), dilation=(32,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (30): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(128,), dilation=(64,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (31): ByteNetBlock(\n",
       "        (conv): MaskedConv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(256,), dilation=(128,))\n",
       "        (sequence1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (4): ReLU()\n",
       "        )\n",
       "        (sequence2): Sequential(\n",
       "          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): ReLU()\n",
       "          (2): PositionFeedForward(\n",
       "            (conv): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): PositionFeedForward(\n",
       "    (conv): Conv1d(1024, 30, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (last_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (loss_func): MaskedCrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA='ACGTN'\n",
    "RNA_ALPHABET = RNA+SPECIALS\n",
    "\n",
    "config={'model':'ByteNetLM',\n",
    "                'lr':1e-3,\n",
    "                'n_tokens':30,\n",
    "                'd_embedding' : 8, # dimension of embedding\n",
    "                'd_model': 1024, # dimension to use within ByteNet model, //2 every layer\n",
    "                'n_layers' : 32, # number of layers of ByteNet block\n",
    "                'activation': 'gelu',\n",
    "                'kernel_size' : 5, # the kernel width\n",
    "                'r' : 128, # used to calculate dilation factor\n",
    "                'padding_idx' : RNA_ALPHABET.index('-') ,# location of padding token in ordered alphabet\n",
    "                'dropout' : 0.1 ,\n",
    "                }\n",
    "\n",
    "model = carp_models.ByteNetLM(config['n_tokens'], config['d_embedding'], config['d_model'],\n",
    "                        config['n_layers'], config['kernel_size'], config['r'], config['lr'],\n",
    "                        padding_idx=config['padding_idx'],dropout=config['dropout'],final_ln=True)\n",
    "model.load_state_dict(torch.load('./protein_model/carp_76M.pt')['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tf_2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8284e1417b754e460c2bde3a4a4837c482fa82ceb7d52f4acbe340dd4b4559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
