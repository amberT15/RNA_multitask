{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('./')\n",
    "\n",
    "from dnabert_datastruct import mask_tokens\n",
    "from dnabert_datastruct import rnabert_maskwrapper,DNATokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import rna_model\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'dnabert_datastruct.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DNATokenizer.from_pretrained('dna6')\n",
    "train_data = rna_model.rna_long_kmer('../data/pre-train/510_6/rna_seq.h5','train',6,tokenizer)\n",
    "valid_data = rna_model.rna_long_kmer('../data/pre-train/510_6/rna_seq.h5','valid',6,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = rnabert_maskwrapper(tokenizer,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_data.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data_collator([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2, 3329, 3318, 2293,   21, 2316, 3150, 1002,   79, 2041, 1798,  108,\n",
       "          1159, 3115, 2696,  549, 1096,    4,  133, 2685, 2121, 2732,    4,   21,\n",
       "           218,    5,  158,    4, 2055,  266, 1369, 1562, 2186, 1030,  104,  661,\n",
       "           343,  429,    4,    4, 2149, 1801, 2709,   39, 1130, 1314, 2444,    4,\n",
       "           212,  198,  477, 1595,  648,    4,  775,  887, 3034, 2145, 3770, 2454,\n",
       "          1430, 1450,    4, 2122,  529,  233, 3668, 3372, 3998, 2406, 1308,  773,\n",
       "          3206, 1617, 3128, 2318, 3933, 1141,  849,  290, 2309, 2329, 2437,  326,\n",
       "            75,  154,  175, 2991, 2054,  521,  250,    8,    4, 2266,   69,    4,\n",
       "           118, 1406, 2461,  101,  157, 1557, 1797, 2261, 1513, 1340, 2069, 3850,\n",
       "          1530, 2501,  620, 1365, 3404, 2519, 2246, 2126, 3576, 2328,    4, 2027,\n",
       "          2001,  810, 2157,  383, 1609, 1710, 3701,   82, 1805, 2339, 1655, 1017,\n",
       "          2118,  328,    4, 1642,  548,    4, 1133,  379, 1084, 2389, 3353, 1387,\n",
       "          1016,   70, 1242, 1533,  674,  545, 3501, 1481,  179,  310, 1309,   45,\n",
       "           330,  117,   34, 1430, 1058, 1193,   89, 1612, 1314, 1371,    4, 2141,\n",
       "           517, 3653, 4002, 1390, 2118,   14,  554, 1573,  533,    4,    4,    4,\n",
       "             4,  347, 1436,  780,  476, 1425, 2396,    4, 3654, 3836, 3993, 1014,\n",
       "          2645,  683, 2029, 2053, 3078,    4,  206, 2057,   85, 1613,    4, 2065,\n",
       "           837, 2826,  233,    4, 3321,  238,  471, 1294, 2298,   95, 1557, 2267,\n",
       "          1858,  981, 1119, 1706, 1353, 3146,  367, 1609, 2249, 2258, 3158,   10,\n",
       "          2029, 1001, 2195, 1500,  493, 4059, 1818, 1606, 2570,  775,  466,    4,\n",
       "          2104, 2635,   14, 3244,    4, 3525,  134, 2321,  350,   14, 3077, 1094,\n",
       "           609,   70,  235,  117,  827,  792,    4,  923,   33,  657,    4, 3080,\n",
       "            25, 1684,  536, 2193,  205,    4,    4, 3280, 1285,  205, 1798, 1005,\n",
       "             4, 3582, 1070, 3340, 2623,   42, 4052, 2568, 3069, 3235, 1491, 1601,\n",
       "          3141, 3240, 2680, 2102,  117,  620, 1641, 2053,   39, 2054, 1261, 3964,\n",
       "          3584, 1935, 1874, 2705, 3228,    4, 1091,  977,  446, 1855, 2296, 3448,\n",
       "          3453, 3537,    4, 1424, 2604, 2143,  172, 3975,    4,    4, 1899,  133,\n",
       "           517, 2055,  453,    4, 1090, 2637, 1099,    4, 3611, 2248, 3273,   38,\n",
       "          3893, 2069, 1480,    4, 1068,   90,   21, 1429,    4, 1178, 1365,   67,\n",
       "             7,  793, 2054,  965, 1173,  868, 2563, 3644, 3430, 3734,  111,  910,\n",
       "          1601, 4065, 3972,    4,  865,    4,    4,    4,  940, 3719,  316,   47,\n",
       "           875, 1173,   23,    4, 1260, 3980, 3388, 2235, 1863, 2707, 1180,    4,\n",
       "          1811,  977,  446, 1807,    4, 3832,    4, 3539, 2854, 2191,  633, 2472,\n",
       "          2692,    4,  904,  621, 1637,    5,    4,    5,  821,    4,   58,   13,\n",
       "             4, 3111, 1877, 2395, 2168,  277, 3346, 3165, 1285,    5,    5,   68,\n",
       "            12, 3433, 3874,    4, 2621,    4, 2501,   37,  547, 2250,  155,    4,\n",
       "           603,    4,  654,  236,    4,  231,    4, 1425,    4,   41,  117,  164,\n",
       "          3118, 3128, 3079, 1797,  264,    4, 1438, 1531,  533, 2305,  531, 1154,\n",
       "          1421, 3721,    4, 3128,    4, 2644,  601, 3490, 2489, 1030, 2038, 2629,\n",
       "             4, 2132,    4, 3132,  776, 1890, 2266, 2281, 2316,  158, 3461, 1797,\n",
       "          1604,  225, 2321,  375,    4,  966, 1154, 3090, 2056, 1077, 2772,   13,\n",
       "          3089,  570, 1365,    6, 3367,    4, 2241, 2200, 1578, 2667, 2387,  633,\n",
       "          3934,    4, 1672, 3220, 2391,    4, 3419,    3]]),\n",
       " 'labels': tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100,  342, 2338, -100, -100, -100, -100,   89, -100,\n",
       "          -100, -100, -100, 1285, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100,   42, 1066, -100, -100, -100, -100, -100, -100, -100, 1643,\n",
       "          -100, -100, -100, -100, -100, 3423, -100, -100, -100, -100, -100, -100,\n",
       "          -100, 1450, 3959, -100, -100, -100, -100, -100, -100, -100,  102, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, 1840, -100, -100,  253,\n",
       "          3645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,  456, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100,  282, -100, -100, 3655, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1479, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, 1873,  980,  546,\n",
       "          3993, -100, -100, -100, -100, -100, -100,  598, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100,  341, -100, -100, -100, -100,  348, -100,\n",
       "          -100, -100, -100, 1004, -100, -100, -100, -100, 2298, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,   72,\n",
       "          -100, -100, -100, -100, 3382, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, 1224, -100, -100, -100,  776, -100,\n",
       "          -100, -100, -100, -100, -100, 3078,  453, -100, -100, -100, -100, -100,\n",
       "          3981, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          3429, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, 4067, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, 3724, -100, -100, -100, -100, -100,  828,  815, -100, -100,\n",
       "          -100, -100, -100, 1221, -100, -100, -100, 2090, -100, -100, -100, -100,\n",
       "          -100, -100, -100,   21, -100, -100, -100, -100,  277, -100, -100, -100,\n",
       "             7, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, 1995, -100, 3944, 3291,  206, -100, -100, -100, -100,\n",
       "          -100, -100, -100,    6, -100, -100, -100, -100, -100, -100, -100, 3907,\n",
       "          -100, -100,  446, -100, 3016, -100, 3453, -100, -100, -100, -100, -100,\n",
       "          -100, 2856, -100, -100, -100, -100,    5, -100, -100,   78, -100, -100,\n",
       "           517, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, 1306, -100,  420, -100, -100, -100, -100,  155, 1369,\n",
       "          -100, 1365, -100, -100,  529, -100,  777, -100, 4005, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, 2462, -100, 1531, -100, -100, -100, -100,\n",
       "          -100, -100, 2296, -100, 3080, -100,  293, -100, -100, -100, -100, -100,\n",
       "          3156, -100, 1832, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100,  841, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100,   79, -100, -100, -100, -100, -100, -100,\n",
       "          -100, 3078, -100, -100, -100, 1666, -100, -100]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2, 3329, 3318, 2293,   21, 2316, 3150, 1002,   79, 2041, 1798,  108,\n",
       "         1159, 3115, 2696,  549, 1096,    4,  133, 2685, 2121, 2732,    4,   21,\n",
       "          218,    5,  158,    4, 2055,  266, 1369, 1562, 2186, 1030,  104,  661,\n",
       "          343,  429,    4,    4, 2149, 1801, 2709,   39, 1130, 1314, 2444,    4,\n",
       "          212,  198,  477, 1595,  648,    4,  775,  887, 3034, 2145, 3770, 2454,\n",
       "         1430, 1450,    4, 2122,  529,  233, 3668, 3372, 3998, 2406, 1308,  773,\n",
       "         3206, 1617, 3128, 2318, 3933, 1141,  849,  290, 2309, 2329, 2437,  326,\n",
       "           75,  154,  175, 2991, 2054,  521,  250,    8,    4, 2266,   69,    4,\n",
       "          118, 1406, 2461,  101,  157, 1557, 1797, 2261, 1513, 1340, 2069, 3850,\n",
       "         1530, 2501,  620, 1365, 3404, 2519, 2246, 2126, 3576, 2328,    4, 2027,\n",
       "         2001,  810, 2157,  383, 1609, 1710, 3701,   82, 1805, 2339, 1655, 1017,\n",
       "         2118,  328,    4, 1642,  548,    4, 1133,  379, 1084, 2389, 3353, 1387,\n",
       "         1016,   70, 1242, 1533,  674,  545, 3501, 1481,  179,  310, 1309,   45,\n",
       "          330,  117,   34, 1430, 1058, 1193,   89, 1612, 1314, 1371,    4, 2141,\n",
       "          517, 3653, 4002, 1390, 2118,   14,  554, 1573,  533,    4,    4,    4,\n",
       "            4,  347, 1436,  780,  476, 1425, 2396,    4, 3654, 3836, 3993, 1014,\n",
       "         2645,  683, 2029, 2053, 3078,    4,  206, 2057,   85, 1613,    4, 2065,\n",
       "          837, 2826,  233,    4, 3321,  238,  471, 1294, 2298,   95, 1557, 2267,\n",
       "         1858,  981, 1119, 1706, 1353, 3146,  367, 1609, 2249, 2258, 3158,   10,\n",
       "         2029, 1001, 2195, 1500,  493, 4059, 1818, 1606, 2570,  775,  466,    4,\n",
       "         2104, 2635,   14, 3244,    4, 3525,  134, 2321,  350,   14, 3077, 1094,\n",
       "          609,   70,  235,  117,  827,  792,    4,  923,   33,  657,    4, 3080,\n",
       "           25, 1684,  536, 2193,  205,    4,    4, 3280, 1285,  205, 1798, 1005,\n",
       "            4, 3582, 1070, 3340, 2623,   42, 4052, 2568, 3069, 3235, 1491, 1601,\n",
       "         3141, 3240, 2680, 2102,  117,  620, 1641, 2053,   39, 2054, 1261, 3964,\n",
       "         3584, 1935, 1874, 2705, 3228,    4, 1091,  977,  446, 1855, 2296, 3448,\n",
       "         3453, 3537,    4, 1424, 2604, 2143,  172, 3975,    4,    4, 1899,  133,\n",
       "          517, 2055,  453,    4, 1090, 2637, 1099,    4, 3611, 2248, 3273,   38,\n",
       "         3893, 2069, 1480,    4, 1068,   90,   21, 1429,    4, 1178, 1365,   67,\n",
       "            7,  793, 2054,  965, 1173,  868, 2563, 3644, 3430, 3734,  111,  910,\n",
       "         1601, 4065, 3972,    4,  865,    4,    4,    4,  940, 3719,  316,   47,\n",
       "          875, 1173,   23,    4, 1260, 3980, 3388, 2235, 1863, 2707, 1180,    4,\n",
       "         1811,  977,  446, 1807,    4, 3832,    4, 3539, 2854, 2191,  633, 2472,\n",
       "         2692,    4,  904,  621, 1637,    5,    4,    5,  821,    4,   58,   13,\n",
       "            4, 3111, 1877, 2395, 2168,  277, 3346, 3165, 1285,    5,    5,   68,\n",
       "           12, 3433, 3874,    4, 2621,    4, 2501,   37,  547, 2250,  155,    4,\n",
       "          603,    4,  654,  236,    4,  231,    4, 1425,    4,   41,  117,  164,\n",
       "         3118, 3128, 3079, 1797,  264,    4, 1438, 1531,  533, 2305,  531, 1154,\n",
       "         1421, 3721,    4, 3128,    4, 2644,  601, 3490, 2489, 1030, 2038, 2629,\n",
       "            4, 2132,    4, 3132,  776, 1890, 2266, 2281, 2316,  158, 3461, 1797,\n",
       "         1604,  225, 2321,  375,    4,  966, 1154, 3090, 2056, 1077, 2772,   13,\n",
       "         3089,  570, 1365,    6, 3367,    4, 2241, 2200, 1578, 2667, 2387,  633,\n",
       "         3934,    4, 1672, 3220, 2391,    4, 3419,    3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg():\n",
    "    def __init__(self,prb):\n",
    "        self.mlm_probability = prb\n",
    "\n",
    "class rnabert_maskwrapper():\n",
    "    def __init__(self,tokenizer,prob_arg) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prb = prob_arg\n",
    "    def __call__(self, batch_entry):\n",
    "        batch_entry = torch.from_numpy(np.array(batch_entry))\n",
    "        input,label = mask_tokens(batch_entry,self.tokenizer,arg(self.prb))\n",
    "        return{'input_ids':input,'labels':label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'dnabert_datastruct.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(rna_model)\n",
    "tokenizer = DNATokenizer.from_pretrained('dna6')\n",
    "train_data = rna_model.rna_kmer('../data/pre-train/510/rna_seq.h5','train',6,tokenizer)\n",
    "valid_data = rna_model.rna_kmer('../data/pre-train/510/rna_seq.h5','valid',6,tokenizer)\n",
    "data_collator = rnabert_maskwrapper(tokenizer,0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False,  True, False, False, False,  True,\n",
      "         False]])\n",
      "tensor([[False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,   11,   12,    4,    4,    4,    4, 1970,    4,    4,    3]]),\n",
       " 'labels': tensor([[-100, -100, -100, -100, -100,   15, -100, -100, -100,   19, -100]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = np.array([2,11,12,13,14,15,16,17,18,19,3])\n",
    "data_collator([test_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tf_2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8284e1417b754e460c2bde3a4a4837c482fa82ceb7d52f4acbe340dd4b4559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
