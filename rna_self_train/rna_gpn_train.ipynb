{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_MASKED_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_TYPES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb Cell 2\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     max_train_samples: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m         default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m         metadata\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m         },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m     max_eval_samples: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m         default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m         metadata\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m         },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m@dataclass\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mModelArguments\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m     model_name_or_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m         default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         metadata\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m         },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m     )\n",
      "\u001b[1;32m/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb Cell 2\u001b[0m in \u001b[0;36mModelArguments\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mArguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m model_name_or_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m     metadata\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m model_type: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m     default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m     metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mhelp\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mIf training from scratch, pass a model type from the list: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(MODEL_TYPES)},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m config_overrides: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m     default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m     metadata\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m config_name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m field(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m     default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mhelp\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPretrained config name or path if not the same as model_name\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcitra/home/amber/multitask_RNA/rna_self_train/rna_gpn_train.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL_TYPES' is not defined"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_fasta_path: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The path to the training fasta file.\"}\n",
    "    )\n",
    "    window_size: Optional[int] = field(\n",
    "        default=None, metadata={\"help\": \"Genomic window size (base pairs)\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    validation_split_percentage: Optional[int] = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
    "        },\n",
    "    )\n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated.\"\n",
    "        },\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    mlm_probability: float = field(\n",
    "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
    "    )\n",
    "    line_by_line: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"},\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization.\"\n",
    "            \"Don't set if you want to train a model from scratch.\"\n",
    "        },\n",
    "    )\n",
    "    model_type: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"If training from scratch, pass a model type from the list: \" + \", \".join(MODEL_TYPES)},\n",
    "    )\n",
    "    config_overrides: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Override some existing default config settings when a model is trained from scratch. Example: \"\n",
    "            \"n_embd=10,resid_pdrop=0.2,scale_attn_weights=false,summary_type=cls_index\"\n",
    "        },\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
    "            \"with private models).\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.config_overrides is not None and (self.config_name is not None or self.model_name_or_path is not None):\n",
    "            raise ValueError(\n",
    "                \"--config_overrides can't be used in combination with --config_name or --model_name_or_path\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CONFIG_MAPPING[model_args.model_type]()\n",
    "if model_args.config_overrides is not None:\n",
    "    logger.info(f\"Overriding config: {model_args.config_overrides}\")\n",
    "    config.update_from_string(model_args.config_overrides)\n",
    "    logger.info(f\"New config: {config}\")\n",
    "model = AutoModelForMaskedLM.from_config(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tf_2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8284e1417b754e460c2bde3a4a4837c482fa82ceb7d52f4acbe340dd4b4559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
