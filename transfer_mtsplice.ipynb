{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5ddb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "import rna_model\n",
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import data_preprocess\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf1b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                              | 203/11840 [00:00<00:05, 2025.97it/s]/home/amber/multitask_RNA/sequence.py:314: UserWarning: Maximum sequence length (0) is less than maxlen (400)\n",
      "  warnings.warn(\"Maximum sequence length (%s) is less than maxlen (%s)\" % (max_seq_len, maxlen))\n",
      "100%|█████████████████████████████| 11840/11840 [00:05<00:00, 2015.15it/s]\n",
      "  3%|▊                             | 1014/38028 [00:00<00:18, 2035.03it/s]/home/amber/multitask_RNA/sequence.py:314: UserWarning: Maximum sequence length (0) is less than maxlen (400)\n",
      "  warnings.warn(\"Maximum sequence length (%s) is less than maxlen (%s)\" % (max_seq_len, maxlen))\n",
      "100%|█████████████████████████████| 38028/38028 [00:18<00:00, 2024.83it/s]\n",
      "100%|███████████████████████████████| 1088/1088 [00:00<00:00, 2023.87it/s]\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('./data/MT_Splice/psi_data.h5', 'w')\n",
    "for dataset in ['test','train','val']:\n",
    "    data_dir = '/home/amber/multitask_RNA/data/MT_Splice/gtex_'+ dataset+'_psi.csv'\n",
    "    data_class = data_preprocess.Ascot(ascot = data_dir,\n",
    "                                  fasta_file = '/home/amber/ref/hg19/hg19.fa',\n",
    "                                  pad_trim_same_l=False, mean_inpute=False,\n",
    "                                  region_anno=False, length=400, flanking=300,\n",
    "                                  seq_align='both', encode=True, flanking_exons=False,use_logit=False)\n",
    "    fa,x,mean,y = [],[],[]\n",
    "    for i in tqdm(range(data_class.__len__())):\n",
    "        item = data_class.__getitem__(i)\n",
    "        fasta = item[0]['fasta']\n",
    "        seq = np.concatenate([item[0]['seql'],item[0]['seqr']])\n",
    "        miu = item[0]['mean']\n",
    "        target = item[1]\n",
    "        \n",
    "        fa.append(fasta)\n",
    "        x.append(seq)\n",
    "        mean.append(miu)\n",
    "        y.append(target)\n",
    "    \n",
    "    if dataset == 'val':\n",
    "        dataset = 'valid'\n",
    "    h5f.create_dataset('x_'+dataset, data=np.asarray(x))\n",
    "    h5f.create_dataset('mean_'+dataset, data=np.asarray(mean))\n",
    "    h5f.create_dataset('y_'+dataset, data=np.asarray(y))\n",
    "    \n",
    "h5f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b45f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('/home/amber/multitask_RNA/data/MT_Splice/psi_data.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f087b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = file['x_train']\n",
    "x_test = file['x_test']\n",
    "x_valid = file['x_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4aa4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.array(['A','C','G','T'])\n",
    "fa_train = []\n",
    "fa_test = []\n",
    "fa_valid = []\n",
    "\n",
    "with open('./data/MT_Splice/valid.fa', 'w') as f:\n",
    "    for i in range(len(x_valid)):\n",
    "        f.write('>exon '+ str(i)+'\\n')\n",
    "        f.write(''.join(alphabet[np.argmax(x_valid[i],axis = 1)])+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0dcaf1b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     fold_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(structure,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     file\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdataset, data\u001b[38;5;241m=\u001b[39mfold_array\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "file = h5py.File('/home/amber/multitask_RNA/data/MT_Splice/psi_data.h5','a')\n",
    "for dataset in ['test','train','valid']:\n",
    "    structure = []\n",
    "    for run in ['M','I','H','E']:\n",
    "        score = open('./data/MT_Splice/'+run+'_'+dataset+'.txt','r').readlines() \n",
    "        score_list = np.char.split(np.array(score), sep ='\\t')\n",
    "        score_array = np.vstack(score_list)[:,:-1]\n",
    "        \n",
    "        structure.append(score_array)\n",
    "    \n",
    "    fold_array = np.stack(structure,axis=1)\n",
    "    file.create_dataset('fold_'+dataset, data=fold_array.astype('float'))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "995a5ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"y_valid\": shape (1088, 56), type \"<f8\">"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f['y_valid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f64c30",
   "metadata": {},
   "source": [
    "## Transfer train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12982d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rna_model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import Trainer\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8a6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = './data/MT_Splice/psi_data.h5'\n",
    "train_loader = DataLoader(rna_model.mt_splice_data(dataset,'train')\n",
    "                    ,num_workers=4,pin_memory=True,batch_size = 32)\n",
    "valid_loader = DataLoader(rna_model.mt_splice_data(dataset,'valid')\n",
    "                    ,num_workers=4,pin_memory=True,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a514c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import rna_model\n",
    "\n",
    "def nan_mask(pred, target):\n",
    "    # Missing data are nan's\n",
    "    mask = torch.isnan(target)\n",
    "    pred = pred[~mask]\n",
    "    target = target[~mask]\n",
    "    return pred,target\n",
    "\n",
    "class transfer_mt_model(pl.LightningModule):\n",
    "    def __init__(self,exp_num,lr):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        \n",
    "        #RBP model\n",
    "        rbp_module = rna_model.rbp_cnn(120,0.001)\n",
    "        rbp_module.load_state_dict(torch.load('/home/amber/multitask_RNA/wandb/run-20220617_144340-m9rrwfw8/files/best_model.ckpt')['state_dict'])\n",
    "        rbp_list = list(rbp_module.children())[2:-4]\n",
    "        self.rbp = torch.nn.Sequential(*[rbp_list[0],rbp_list[1][:-5]])\n",
    "#         for param in self.rbp.parameters():\n",
    "#             param.requires_grad = False\n",
    "        #Annotation model\n",
    "        annot_model = rna_model.Splice_AI_2K((4,800),(3,800),32,0.001)\n",
    "        annot_model.load_state_dict(torch.load('/home/amber/multitask_RNA/wandb/run-20220612_213207-zai2tsbz/files/best_model.ckpt')['state_dict'])\n",
    "        self.annot = torch.nn.Sequential(*list(annot_model.children())[2:-3])\n",
    "#         for param in self.annot.parameters():\n",
    "#             param.requires_grad = False\n",
    "        #outputhead\n",
    "        #(N,37,800)\n",
    "        self.outblock = torch.nn.Sequential(*[\n",
    "            nn.Conv1d(37,128,8,padding = 'same'),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv1d(128,256,3,padding = 'same'),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv1d(256,256,3,padding = 'same'),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3072,256),\n",
    "            nn.Linear(256,256),\n",
    "            nn.Linear(256,exp_num),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "        self.loss_func = torch.nn.KLDivLoss()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        seq = x[0]\n",
    "        seq_fold = x[1]\n",
    "        rbp_pres = self.rbp(seq)\n",
    "        rbp_pres = torch.nn.functional.pad(rbp_pres,(0,0,144,144,0,0))\n",
    "        rbp_pres = rbp_pres.permute((0,2,1))\n",
    "        annot_pres = self.annot(seq)\n",
    "        pres = torch.cat((annot_pres,rbp_pres,seq_fold),dim=1)\n",
    "        output = self.outblock(pres)\n",
    "        return output\n",
    "        \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat,y = nan_mask(y_hat,y)\n",
    "        y0 = torch.log(y_hat)\n",
    "        y1 = torch.log(1-y_hat)\n",
    "        loss0 = self.loss_func(y0,y)\n",
    "        loss1 = self.loss_func(y1,1-y)\n",
    "        loss = loss0+loss1\n",
    "        self.log(\"train_loss\", loss,on_step = False, on_epoch = True)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat,y = nan_mask(y_hat,y)\n",
    "        y0 = torch.log(y_hat)\n",
    "        y1 = torch.log(1-y_hat)\n",
    "        loss0 = self.loss_func(y0,y)\n",
    "        loss1 = self.loss_func(y1,1-y)\n",
    "        loss = loss0+loss1\n",
    "        self.log(\"val_loss\", loss,on_step = False, on_epoch = True)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        self.opt=torch.optim.Adam([{\"params\":self.rbp.parameters(),\"lr\": 1e-5},\n",
    "                                   {\"params\":self.annot.parameters(),\"lr\": 1e-5},\n",
    "                                   {\"params\":self.outblock.parameters(),\"lr\": 1e-3}])\n",
    "\n",
    "        self.reduce_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(self.opt,\n",
    "                                                                     mode = 'min',\n",
    "                                                                     factor = 0.2,\n",
    "                                                                    patience = 3,\n",
    "                                                                    min_lr = 1e-7,\n",
    "                                                                    verbose = True)\n",
    "        schedulers =  {'scheduler':self.reduce_lr,'monitor':\"val_loss\",}\n",
    "        return [self.opt],schedulers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c875705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mambert\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/amber/multitask_RNA/wandb/run-20220621_105308-gkno7e37</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ambert/mt_splice/runs/gkno7e37\" target=\"_blank\">quiet-monkey-2</a></strong> to <a href=\"https://wandb.ai/ambert/mt_splice\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = transfer_mt_model(56,0.001)\n",
    "config={'model':'transfer_mt_model','lr':1e-3,'t_lr':1e-5}\n",
    "wandb_logger = WandbLogger(project=\"mt_splice\",config=config,log_model=True)\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1,\n",
    "                                        monitor=\"val_loss\",\n",
    "                                        mode=\"min\",\n",
    "                                        dirpath=wandb.run.dir,\n",
    "                                        filename=\"best_model\")\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\",\n",
    "                            mode=\"min\",patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48c8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1,detect_anomaly=True,max_epochs=100,logger = wandb_logger,\n",
    "                    callbacks=[checkpoint_callback,earlystop,lr_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c3d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amber/tf_2/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/amber/multitask_RNA/wandb/run-20220621_105308-gkno7e37/files exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | rbp       | Sequential | 2.2 M \n",
      "1 | annot     | Sequential | 358 K \n",
      "2 | outblock  | Sequential | 1.2 M \n",
      "3 | loss_func | KLDivLoss  | 0     \n",
      "-----------------------------------------\n",
      "3.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.7 M     Total params\n",
      "14.880    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amber/tf_2/lib/python3.8/site-packages/torch/nn/modules/conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/amber/tf_2/lib/python3.8/site-packages/torch/nn/functional.py:2886: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "/home/amber/tf_2/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef01c7810e54626a3a0e55b2e658ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: reducing learning rate of group 0 to 2.0000e-06.\n",
      "Epoch 00005: reducing learning rate of group 1 to 2.0000e-06.\n",
      "Epoch 00005: reducing learning rate of group 2 to 2.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: reducing learning rate of group 0 to 4.0000e-07.\n",
      "Epoch 00009: reducing learning rate of group 1 to 4.0000e-07.\n",
      "Epoch 00009: reducing learning rate of group 2 to 4.0000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=model,train_dataloaders=train_loader,val_dataloaders = valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2fb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
