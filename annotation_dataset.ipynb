{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b187095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1f63d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3457723/1529983734.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  annotation_df = annotation_df.drop('Phase', 1)\n",
      "/tmp/ipykernel_3457723/1529983734.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  annotation_df = annotation_df.drop('Score', 1)\n"
     ]
    }
   ],
   "source": [
    "colnames=['Chrom', 'Database', 'Annotation', 'Start','End','Score','Strand','Phase','Notes'] \n",
    "annotation_df = pd.read_csv('/home/amber/multitask_RNA/data/annotation/gencode.v40.annotation.gtf',\n",
    "                            sep='\\t',skiprows=5,names=colnames,header=None)\n",
    "annotation_df = annotation_df.drop('Phase', 1)\n",
    "annotation_df = annotation_df.drop('Score', 1)\n",
    "annotation_df['GeneID'] = annotation_df['Notes'].apply(lambda x: x.split('\"')[1])\n",
    "annotation_df['TranscriptID'] = annotation_df['Notes'].apply(lambda x : x.split('\"')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716fc59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 61544/61544 [37:39<00:00, 27.24it/s]\n"
     ]
    }
   ],
   "source": [
    "trans_id_list = []\n",
    "gene_list = annotation_df['GeneID'].unique()\n",
    "all_transcript_df = annotation_df[annotation_df['Annotation'] == 'transcript']\n",
    "for gene in tqdm(gene_list,total=len(gene_list)):\n",
    "    transcript_df = all_transcript_df[all_transcript_df['GeneID']==gene]\n",
    "    trans_length = transcript_df['End'] - transcript_df['Start']\n",
    "    max_trans_index = np.argmax(trans_length)\n",
    "    max_trans = transcript_df.iloc[max_trans_index]\n",
    "    max_id = max_trans['Notes'].split('\"')[3]\n",
    "    trans_id_list.append(max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f0bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_flag = (annotation_df['Annotation']=='gene')\n",
    "transcript_flag = (annotation_df['TranscriptID'].isin(trans_id_list))\n",
    "cannonical_flag = np.array(gene_flag) + np.array(transcript_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6c91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cannonical_df = annotation_df[cannonical_flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae87f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696277"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cannonical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20dfba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cannonical_df.to_csv('./data/annotation/cannonical_annotation.csv',sep='\\t',\n",
    "                     columns=['Chrom', 'Database', 'Annotation', 'Start','End','Strand','GeneID','TranscriptID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a3315",
   "metadata": {},
   "source": [
    "## Creating corresponding label from selected cannonical annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9a9bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027b9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df = pd.read_csv('./data/annotation/cannonical_annotation.csv',sep='\\t',index_col=0)\n",
    "annot_df=annot_df[annot_df['Annotation'] != 'gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b7a1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634733"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e4f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create label for 3'/5' splice sites, UTR, CDS, Exon, or non of the above\n",
    "#Use cannonical transcript(longest transcript per gene)\n",
    "def format_list(label_list):\n",
    "    if len(label_list)==0:\n",
    "        return 'NA'\n",
    "    else: return ','.join(list(map(str, label_list)))\n",
    "\n",
    "table_content=['Gene','Chr','Strand','Start','End',\"Donor\",\"Acceptor\",\"UTR\",'CDS','Exon']\n",
    "with open('./data/annotation/annot_label.csv','w') as file:\n",
    "    for index,row in annot_df.iterrows():\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        if row['Annotation'] == 'transcript':\n",
    "            if index != 1:\n",
    "                table_content=[transcript_info[0],\n",
    "                             str(transcript_info[1]),\n",
    "                              str(transcript_info[2]),\n",
    "                               str(transcript_info[3]),\n",
    "                               str(transcript_info[4]),\n",
    "                              format_list(donor_list[:-1]),\n",
    "                              format_list(acceptor_list[1:]),\n",
    "                              format_list(utr_list),\n",
    "                              format_list(cds_list),\n",
    "                              format_list(exon_list)]\n",
    "            file.write('\\t'.join(table_content)+'\\n')\n",
    "            utr_list = []\n",
    "            cds_list = []\n",
    "            acceptor_list = []\n",
    "            donor_list = []\n",
    "            exon_list = []\n",
    "            transcript_info = [row['GeneID'],row['Chrom'],row['Strand'],start,end]\n",
    "        elif row['Annotation'] == 'UTR':\n",
    "            utr_list.append(\"%s-%s\" %(start,end))\n",
    "        elif row['Annotation'] == 'CDS':\n",
    "            cds_list.append(\"%s-%s\" %(start,end))\n",
    "        elif row['Annotation'] == 'exon':\n",
    "            exon_list.append(\"%s-%s\" %(start,end))\n",
    "            if row['Strand'] == '+':\n",
    "                acceptor_list.append(start)\n",
    "                donor_list.append(end)\n",
    "            elif row['Strand'] == '-':\n",
    "                acceptor_list.append(end)\n",
    "                donor_list.append(start)\n",
    "    file.write('\\t'.join(table_content)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ba444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ./data/annotation/annot_label.csv | awk -v CLl=1 -v CLr=0 '{print $2\"\\t\"($4-CLl)\"\\t\"($5+CLr)}' > ./data/annotation/temp.bed\n",
    "! sed -i '1d' ./data/annotation/temp.bed \n",
    "! grep -v \"chrM\" ./data/annotation/temp.bed > ./data/annotation/seq.bed\n",
    "! rm ./data/annotation/temp.bed\n",
    "!bedtools getfasta -bed ./data/annotation/seq.bed -fi /home/amber/ref/hg38/hg38.fa -fo ./data/annotation/seq.txt -tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5448270",
   "metadata": {},
   "source": [
    "## Create vector lable containing variable tasks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f662c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import data_preprocess\n",
    "padding = 80\n",
    "seq_len = 5000\n",
    "#Splice donor/acceptor is alwasy included. Other possible lables:\n",
    "#[UTR,CDS,Exon]\n",
    "task_list = []\n",
    "task_count = len(task_list) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c754bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('./data/annotation/annot_label.csv',sep='\\t')\n",
    "label_df = label_df[label_df['Chr']!='chrM']\n",
    "seq_file = open('./data/annotation/seq.txt', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37094ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine final sequenc size\n",
    "train_chrom =['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7',\n",
    "              'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15',\n",
    "              'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', \n",
    "              'chr22', 'chrX', 'chrY']\n",
    "valid_chrom = ['chr8']\n",
    "test_chrom = ['chr9']\n",
    "train_c,valid_c,test_c=0,0,0\n",
    "for i in range(len(label_df)):\n",
    "    row = label_df.iloc[i]\n",
    "    chrom = row['Chr']\n",
    "    start = row['Start']\n",
    "    end = row['End']\n",
    "    length = end - start + 1\n",
    "    count = -1 * (-length // seq_len)\n",
    "    if chrom in train_chrom:\n",
    "        train_c += count\n",
    "    elif chrom in valid_chrom:\n",
    "        valid_c += count\n",
    "    elif chrom in test_chrom:\n",
    "        test_c += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be2e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = str(seq_len) + '_'+str(padding)+'.h5'\n",
    "h5f = h5py.File('./data/annotation/'+file_name, 'w')\n",
    "x_train = h5f.create_dataset('x_train',shape=(train_c,padding+seq_len,4),dtype=np.int8)\n",
    "x_valid = h5f.create_dataset('x_valid', shape=(valid_c,padding+seq_len,4),dtype=np.int8)\n",
    "x_test = h5f.create_dataset('x_test', shape=(test_c,padding+seq_len,4),dtype=np.int8)\n",
    "y_train = h5f.create_dataset('y_train', shape=(train_c,seq_len,task_count),dtype=np.int8)\n",
    "y_valid = h5f.create_dataset('y_valid', shape=(valid_c,seq_len,task_count),dtype=np.int8)\n",
    "y_test = h5f.create_dataset('y_test', shape=(test_c,seq_len,task_count),dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa5dd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 61507/61507 [05:09<00:00, 198.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_i = 0\n",
    "valid_i = 0\n",
    "test_i = 0\n",
    "for idx in tqdm(range(len(label_df))):\n",
    "    seq = seq_file[idx]\n",
    "    row = label_df.iloc[idx]\n",
    "    chrom = row['Chr']\n",
    "    X,Y = data_preprocess.create_datapoints(seq,row,seq_len,padding,task_list)\n",
    "    X = np.asarray(X,dtype=np.int8)\n",
    "    Y = np.asarray(Y,dtype=np.int8)\n",
    "    test_sum = np.sum(Y,axis=2)\n",
    "    if chrom in train_chrom:\n",
    "        x_train[train_i:train_i+len(X)]=X\n",
    "        y_train[train_i:train_i+len(X)]=Y\n",
    "        train_i = train_i+len(X)\n",
    "    elif chrom in valid_chrom:\n",
    "        x_valid[valid_i:valid_i+len(X)]=X\n",
    "        y_valid[valid_i:valid_i+len(X)]=Y\n",
    "        valid_i = valid_i+len(X)\n",
    "    elif chrom in test_chrom:\n",
    "        x_test[test_i:test_i+len(X)]=X\n",
    "        y_test[test_i:test_i+len(X)]=Y\n",
    "        test_i = test_i+len(X)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ad5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./data/annotation/'+file_name, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e68faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argwhere(np.sum(h5f['y_train'],axis=2) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82791544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a358931",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe6ae8",
   "metadata": {},
   "source": [
    "## Convert SpliceAI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f8b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0e3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./SpliceAI80/dataset_train_all.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f974e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_idx = len(h5f.keys())//2\n",
    "idx_all = np.random.permutation(num_idx)\n",
    "idx_train = idx_all[:int(0.9*num_idx)]\n",
    "idx_valid = idx_all[int(0.9*num_idx):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03144f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 119/119 [00:01<00:00, 106.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x=[]\n",
    "train_y=[]\n",
    "for i in tqdm(idx_train):\n",
    "    X = h5f['X' + str(i)][:]\n",
    "    Y = h5f['Y' + str(i)][:]\n",
    "    train_x.append(X)\n",
    "    train_y.append(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f04f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(train_x)\n",
    "y_train = np.concatenate(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7809bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 14/14 [00:00<00:00, 106.23it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_x=[]\n",
    "valid_y=[]\n",
    "for i in tqdm(idx_valid):\n",
    "    X = h5f['X' + str(i)][:]\n",
    "    Y = h5f['Y' + str(i)][:]\n",
    "    valid_x.append(X)\n",
    "    valid_y.append(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850b3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = np.concatenate(valid_x)\n",
    "y_valid = np.concatenate(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801ef921",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a9f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./SpliceAI80/dataset_test_0.h5', 'r')\n",
    "num_idx = len(h5f.keys())//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363578ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 16/16 [00:00<00:00, 119.90it/s]\n"
     ]
    }
   ],
   "source": [
    "test_x=[]\n",
    "test_y=[]\n",
    "for i in tqdm(range(num_idx)):\n",
    "    X = h5f['X' + str(i)][:]\n",
    "    Y = h5f['Y' + str(i)][:]\n",
    "    test_x.append(X)\n",
    "    test_y.append(Y[0])\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ea1add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16505, 5000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.concatenate(test_x)\n",
    "y_test = np.concatenate(test_y)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fe5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('./data/annotation/spliceai_5000_80.h5', 'w')\n",
    "h5f.create_dataset('x_train', data=np.asarray(x_train).astype('int8'))\n",
    "h5f.create_dataset('x_valid', data=np.asarray(x_valid).astype('int8'))\n",
    "h5f.create_dataset('x_test', data=np.asarray(x_test).astype('int8'))\n",
    "h5f.create_dataset('y_train', data=np.asarray(y_train).astype('int8'))\n",
    "h5f.create_dataset('y_valid', data=np.asarray(y_valid).astype('int8'))\n",
    "h5f.create_dataset('y_test', data=np.asarray(y_test).astype('int8'))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5600254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
